{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/400], Loss: 6.9463\n",
      "Epoch [2/400], Loss: 6.7661\n",
      "Epoch [3/400], Loss: 6.6305\n",
      "Epoch [4/400], Loss: 6.5433\n",
      "Epoch [5/400], Loss: 6.4614\n",
      "Epoch [6/400], Loss: 6.4041\n",
      "Epoch [7/400], Loss: 6.3500\n",
      "Epoch [8/400], Loss: 6.3038\n",
      "Epoch [9/400], Loss: 6.2798\n",
      "Epoch [10/400], Loss: 6.2519\n",
      "Epoch [11/400], Loss: 6.2342\n",
      "Epoch [12/400], Loss: 6.2201\n",
      "Epoch [13/400], Loss: 6.2054\n",
      "Epoch [14/400], Loss: 6.1953\n",
      "Epoch [15/400], Loss: 6.1769\n",
      "Epoch [16/400], Loss: 6.1681\n",
      "Epoch [17/400], Loss: 6.1672\n",
      "Epoch [18/400], Loss: 6.1634\n",
      "Epoch [19/400], Loss: 6.1573\n",
      "Epoch [20/400], Loss: 6.1599\n",
      "Epoch [21/400], Loss: 6.1540\n",
      "Epoch [22/400], Loss: 6.1524\n",
      "Epoch [23/400], Loss: 6.1512\n",
      "Epoch [24/400], Loss: 6.1542\n",
      "Epoch [25/400], Loss: 6.1537\n",
      "Epoch [26/400], Loss: 6.1434\n",
      "Epoch [27/400], Loss: 6.1412\n",
      "Epoch [28/400], Loss: 6.1483\n",
      "Epoch [29/400], Loss: 6.1372\n",
      "Epoch [30/400], Loss: 6.1430\n",
      "Epoch [31/400], Loss: 6.1463\n",
      "Epoch [32/400], Loss: 6.1478\n",
      "Epoch [33/400], Loss: 6.1328\n",
      "Epoch [34/400], Loss: 6.1485\n",
      "Epoch [35/400], Loss: 6.1493\n",
      "Epoch [36/400], Loss: 6.1652\n",
      "Epoch [37/400], Loss: 6.1414\n",
      "Epoch [38/400], Loss: 6.1515\n",
      "Epoch [39/400], Loss: 6.1613\n",
      "Epoch [40/400], Loss: 6.1445\n",
      "Epoch [41/400], Loss: 6.1489\n",
      "Epoch [42/400], Loss: 6.1526\n",
      "Epoch [43/400], Loss: 6.1464\n",
      "Epoch [44/400], Loss: 6.1490\n",
      "Epoch [45/400], Loss: 6.1561\n",
      "Epoch [46/400], Loss: 6.1504\n",
      "Epoch [47/400], Loss: 6.1448\n",
      "Epoch [48/400], Loss: 6.1590\n",
      "Epoch [49/400], Loss: 6.1639\n",
      "Epoch [50/400], Loss: 6.1503\n",
      "Epoch [51/400], Loss: 6.1308\n",
      "Epoch [52/400], Loss: 6.1424\n",
      "Epoch [53/400], Loss: 6.1323\n",
      "Epoch [54/400], Loss: 6.1271\n",
      "Epoch [55/400], Loss: 6.1423\n",
      "Epoch [56/400], Loss: 6.1579\n",
      "Epoch [57/400], Loss: 6.1624\n",
      "Epoch [58/400], Loss: 6.1547\n",
      "Epoch [59/400], Loss: 6.1454\n",
      "Epoch [60/400], Loss: 6.1644\n",
      "Epoch [61/400], Loss: 6.1696\n",
      "Epoch [62/400], Loss: 6.1797\n",
      "Epoch [63/400], Loss: 6.1762\n",
      "Epoch [64/400], Loss: 6.1822\n",
      "Epoch [65/400], Loss: 6.1841\n",
      "Epoch [66/400], Loss: 6.2021\n",
      "Epoch [67/400], Loss: 6.2291\n",
      "Epoch [68/400], Loss: 6.2047\n",
      "Epoch [69/400], Loss: 6.2188\n",
      "Epoch [70/400], Loss: 6.2216\n",
      "Epoch [71/400], Loss: 6.2500\n",
      "Epoch [72/400], Loss: 6.2951\n",
      "Epoch [73/400], Loss: 6.2323\n",
      "Epoch [74/400], Loss: 6.2297\n",
      "Epoch [75/400], Loss: 6.2408\n",
      "Epoch [76/400], Loss: 6.2493\n",
      "Epoch [77/400], Loss: 6.2779\n",
      "Epoch [78/400], Loss: 6.2579\n",
      "Epoch [79/400], Loss: 6.2544\n",
      "Epoch [80/400], Loss: 6.3317\n",
      "Epoch [81/400], Loss: 6.3056\n",
      "Epoch [82/400], Loss: 6.2783\n",
      "Epoch [83/400], Loss: 6.2730\n",
      "Epoch [84/400], Loss: 6.2774\n",
      "Epoch [85/400], Loss: 6.2807\n",
      "Epoch [86/400], Loss: 6.2840\n",
      "Epoch [87/400], Loss: 6.3103\n",
      "Epoch [88/400], Loss: 6.2883\n",
      "Epoch [89/400], Loss: 6.3012\n",
      "Epoch [90/400], Loss: 6.2905\n",
      "Epoch [91/400], Loss: 6.3117\n",
      "Epoch [92/400], Loss: 6.3270\n",
      "Epoch [93/400], Loss: 6.3217\n",
      "Epoch [94/400], Loss: 6.3059\n",
      "Epoch [95/400], Loss: 6.3280\n",
      "Epoch [96/400], Loss: 6.3125\n",
      "Epoch [97/400], Loss: 6.3044\n",
      "Epoch [98/400], Loss: 6.3167\n",
      "Epoch [99/400], Loss: 6.3265\n",
      "Epoch [100/400], Loss: 6.4051\n",
      "Epoch [101/400], Loss: 6.4156\n",
      "Epoch [102/400], Loss: 6.3593\n",
      "Epoch [103/400], Loss: 6.3345\n",
      "Epoch [104/400], Loss: 6.3381\n",
      "Epoch [105/400], Loss: 6.3424\n",
      "Epoch [106/400], Loss: 6.3503\n",
      "Epoch [107/400], Loss: 6.3613\n",
      "Epoch [108/400], Loss: 6.3648\n",
      "Epoch [109/400], Loss: 6.3509\n",
      "Epoch [110/400], Loss: 6.3511\n",
      "Epoch [111/400], Loss: 6.3493\n",
      "Epoch [112/400], Loss: 6.3712\n",
      "Epoch [113/400], Loss: 6.3748\n",
      "Epoch [114/400], Loss: 6.3344\n",
      "Epoch [115/400], Loss: 6.3647\n",
      "Epoch [116/400], Loss: 6.3635\n",
      "Epoch [117/400], Loss: 6.3555\n",
      "Epoch [118/400], Loss: 6.3501\n",
      "Epoch [119/400], Loss: 6.3498\n",
      "Epoch [120/400], Loss: 6.3607\n",
      "Epoch [121/400], Loss: 6.3535\n",
      "Epoch [122/400], Loss: 6.3707\n",
      "Epoch [123/400], Loss: 6.3409\n",
      "Epoch [124/400], Loss: 6.3833\n",
      "Epoch [125/400], Loss: 6.3605\n",
      "Epoch [126/400], Loss: 6.3554\n",
      "Epoch [127/400], Loss: 6.3704\n",
      "Epoch [128/400], Loss: 6.3641\n",
      "Epoch [129/400], Loss: 6.3804\n",
      "Epoch [130/400], Loss: 6.3716\n",
      "Epoch [131/400], Loss: 6.3831\n",
      "Epoch [132/400], Loss: 6.3947\n",
      "Epoch [133/400], Loss: 6.3806\n",
      "Epoch [134/400], Loss: 6.3895\n",
      "Epoch [135/400], Loss: 6.3773\n",
      "Epoch [136/400], Loss: 6.4287\n",
      "Epoch [137/400], Loss: 6.3946\n",
      "Epoch [138/400], Loss: 6.4582\n",
      "Epoch [139/400], Loss: 6.4166\n",
      "Epoch [140/400], Loss: 6.3863\n",
      "Epoch [141/400], Loss: 6.3883\n",
      "Epoch [142/400], Loss: 6.3898\n",
      "Epoch [143/400], Loss: 6.4053\n",
      "Epoch [144/400], Loss: 6.4096\n",
      "Epoch [145/400], Loss: 6.3956\n",
      "Epoch [146/400], Loss: 6.4348\n",
      "Epoch [147/400], Loss: 6.4057\n",
      "Epoch [148/400], Loss: 6.4040\n",
      "Epoch [149/400], Loss: 6.5058\n",
      "Epoch [150/400], Loss: 6.4574\n",
      "Epoch [151/400], Loss: 6.4341\n",
      "Epoch [152/400], Loss: 6.4316\n",
      "Epoch [153/400], Loss: 6.4260\n",
      "Epoch [154/400], Loss: 6.4505\n",
      "Epoch [155/400], Loss: 6.4478\n",
      "Epoch [156/400], Loss: 6.4417\n",
      "Epoch [157/400], Loss: 6.4363\n",
      "Epoch [158/400], Loss: 6.4595\n",
      "Epoch [159/400], Loss: 6.4430\n",
      "Epoch [160/400], Loss: 6.4435\n",
      "Epoch [161/400], Loss: 6.4949\n",
      "Epoch [162/400], Loss: 6.4556\n",
      "Epoch [163/400], Loss: 6.4409\n",
      "Epoch [164/400], Loss: 6.4718\n",
      "Epoch [165/400], Loss: 6.4840\n",
      "Epoch [166/400], Loss: 6.4233\n",
      "Epoch [167/400], Loss: 6.4665\n",
      "Epoch [168/400], Loss: 6.4553\n",
      "Epoch [169/400], Loss: 6.4522\n",
      "Epoch [170/400], Loss: 6.4615\n",
      "Epoch [171/400], Loss: 6.4509\n",
      "Epoch [172/400], Loss: 6.4798\n",
      "Epoch [173/400], Loss: 6.4627\n",
      "Epoch [174/400], Loss: 6.4604\n",
      "Epoch [175/400], Loss: 6.5002\n",
      "Epoch [176/400], Loss: 6.4830\n",
      "Epoch [177/400], Loss: 6.5010\n",
      "Epoch [178/400], Loss: 6.5070\n",
      "Epoch [179/400], Loss: 6.5131\n",
      "Epoch [180/400], Loss: 6.5378\n",
      "Epoch [181/400], Loss: 6.4777\n",
      "Epoch [182/400], Loss: 6.5105\n",
      "Epoch [183/400], Loss: 6.4920\n",
      "Epoch [184/400], Loss: 6.5294\n",
      "Epoch [185/400], Loss: 6.5125\n",
      "Epoch [186/400], Loss: 6.5082\n",
      "Epoch [187/400], Loss: 6.5698\n",
      "Epoch [188/400], Loss: 6.5381\n",
      "Epoch [189/400], Loss: 6.4936\n",
      "Epoch [190/400], Loss: 6.5664\n",
      "Epoch [191/400], Loss: 6.6178\n",
      "Epoch [192/400], Loss: 6.5022\n",
      "Epoch [193/400], Loss: 6.5311\n",
      "Epoch [194/400], Loss: 6.5946\n",
      "Epoch [195/400], Loss: 6.5395\n",
      "Epoch [196/400], Loss: 6.5366\n",
      "Epoch [197/400], Loss: 6.5118\n",
      "Epoch [198/400], Loss: 6.6199\n",
      "Epoch [199/400], Loss: 6.6052\n",
      "Epoch [200/400], Loss: 6.5946\n",
      "Epoch [201/400], Loss: 6.5814\n",
      "Epoch [202/400], Loss: 6.6266\n",
      "Epoch [203/400], Loss: 6.5650\n",
      "Epoch [204/400], Loss: 6.5482\n",
      "Epoch [205/400], Loss: 6.5530\n",
      "Epoch [206/400], Loss: 6.5619\n",
      "Epoch [207/400], Loss: 6.5146\n",
      "Epoch [208/400], Loss: 6.5357\n",
      "Epoch [209/400], Loss: 6.5171\n",
      "Epoch [210/400], Loss: 6.5308\n",
      "Epoch [211/400], Loss: 6.5335\n",
      "Epoch [212/400], Loss: 6.5519\n",
      "Epoch [213/400], Loss: 6.5412\n",
      "Epoch [214/400], Loss: 6.5418\n",
      "Epoch [215/400], Loss: 6.5282\n",
      "Epoch [216/400], Loss: 6.5158\n",
      "Epoch [217/400], Loss: 6.5815\n",
      "Epoch [218/400], Loss: 6.5856\n",
      "Epoch [219/400], Loss: 6.5592\n",
      "Epoch [220/400], Loss: 6.5503\n",
      "Epoch [221/400], Loss: 6.5328\n",
      "Epoch [222/400], Loss: 6.5215\n",
      "Epoch [223/400], Loss: 6.5043\n",
      "Epoch [224/400], Loss: 6.5479\n",
      "Epoch [225/400], Loss: 6.4993\n",
      "Epoch [226/400], Loss: 6.5356\n",
      "Epoch [227/400], Loss: 6.5598\n",
      "Epoch [228/400], Loss: 6.5037\n",
      "Epoch [229/400], Loss: 6.5937\n",
      "Epoch [230/400], Loss: 6.5125\n",
      "Epoch [231/400], Loss: 6.6013\n",
      "Epoch [232/400], Loss: 6.5083\n",
      "Epoch [233/400], Loss: 6.5291\n",
      "Epoch [234/400], Loss: 6.5317\n",
      "Epoch [235/400], Loss: 6.5083\n",
      "Epoch [236/400], Loss: 6.6108\n",
      "Epoch [237/400], Loss: 6.5198\n",
      "Epoch [238/400], Loss: 6.5496\n",
      "Epoch [239/400], Loss: 6.5356\n",
      "Epoch [240/400], Loss: 6.5272\n",
      "Epoch [241/400], Loss: 6.5718\n",
      "Epoch [242/400], Loss: 6.5179\n",
      "Epoch [243/400], Loss: 6.5713\n",
      "Epoch [244/400], Loss: 6.5388\n",
      "Epoch [245/400], Loss: 6.5390\n",
      "Epoch [246/400], Loss: 6.5739\n",
      "Epoch [247/400], Loss: 6.5238\n",
      "Epoch [248/400], Loss: 6.5327\n",
      "Epoch [249/400], Loss: 6.5218\n",
      "Epoch [250/400], Loss: 6.5779\n",
      "Epoch [251/400], Loss: 6.5564\n",
      "Epoch [252/400], Loss: 6.5373\n",
      "Epoch [253/400], Loss: 6.5501\n",
      "Epoch [254/400], Loss: 6.5512\n",
      "Epoch [255/400], Loss: 6.5379\n",
      "Epoch [256/400], Loss: 6.5263\n",
      "Epoch [257/400], Loss: 6.5469\n",
      "Epoch [258/400], Loss: 6.5602\n",
      "Epoch [259/400], Loss: 6.6209\n",
      "Epoch [260/400], Loss: 6.5879\n",
      "Epoch [261/400], Loss: 6.5391\n",
      "Epoch [262/400], Loss: 6.5683\n",
      "Epoch [263/400], Loss: 6.5701\n",
      "Epoch [264/400], Loss: 6.6278\n",
      "Epoch [265/400], Loss: 6.5747\n",
      "Epoch [266/400], Loss: 6.5938\n",
      "Epoch [267/400], Loss: 6.5641\n",
      "Epoch [268/400], Loss: 6.5771\n",
      "Epoch [269/400], Loss: 6.5393\n",
      "Epoch [270/400], Loss: 6.5562\n",
      "Epoch [271/400], Loss: 6.5703\n",
      "Epoch [272/400], Loss: 6.5742\n",
      "Epoch [273/400], Loss: 6.5514\n",
      "Epoch [274/400], Loss: 6.5461\n",
      "Epoch [275/400], Loss: 6.5260\n",
      "Epoch [276/400], Loss: 6.5535\n",
      "Epoch [277/400], Loss: 6.5591\n",
      "Epoch [278/400], Loss: 6.6416\n",
      "Epoch [279/400], Loss: 6.5449\n",
      "Epoch [280/400], Loss: 6.6615\n",
      "Epoch [281/400], Loss: 6.5395\n",
      "Epoch [282/400], Loss: 6.5483\n",
      "Epoch [283/400], Loss: 6.5453\n",
      "Epoch [284/400], Loss: 6.5346\n",
      "Epoch [285/400], Loss: 6.5345\n",
      "Epoch [286/400], Loss: 6.5548\n",
      "Epoch [287/400], Loss: 6.5265\n",
      "Epoch [288/400], Loss: 6.5736\n",
      "Epoch [289/400], Loss: 6.5233\n",
      "Epoch [290/400], Loss: 6.5560\n",
      "Epoch [291/400], Loss: 6.5381\n",
      "Epoch [292/400], Loss: 6.5003\n",
      "Epoch [293/400], Loss: 6.5119\n",
      "Epoch [294/400], Loss: 6.5541\n",
      "Epoch [295/400], Loss: 6.5208\n",
      "Epoch [296/400], Loss: 6.5131\n",
      "Epoch [297/400], Loss: 6.5434\n",
      "Epoch [298/400], Loss: 6.5312\n",
      "Epoch [299/400], Loss: 6.5026\n",
      "Epoch [300/400], Loss: 6.5086\n",
      "Epoch [301/400], Loss: 6.5508\n",
      "Epoch [302/400], Loss: 6.5937\n",
      "Epoch [303/400], Loss: 6.5718\n",
      "Epoch [304/400], Loss: 6.5181\n",
      "Epoch [305/400], Loss: 6.5084\n",
      "Epoch [306/400], Loss: 6.5348\n",
      "Epoch [307/400], Loss: 6.5338\n",
      "Epoch [308/400], Loss: 6.5079\n",
      "Epoch [309/400], Loss: 6.5439\n",
      "Epoch [310/400], Loss: 6.5140\n",
      "Epoch [311/400], Loss: 6.5156\n",
      "Epoch [312/400], Loss: 6.5291\n",
      "Epoch [313/400], Loss: 6.5378\n",
      "Epoch [314/400], Loss: 6.5212\n",
      "Epoch [315/400], Loss: 6.5312\n",
      "Epoch [316/400], Loss: 6.5358\n",
      "Epoch [317/400], Loss: 6.5459\n",
      "Epoch [318/400], Loss: 6.6024\n",
      "Epoch [319/400], Loss: 6.5310\n",
      "Epoch [320/400], Loss: 6.5165\n",
      "Epoch [321/400], Loss: 6.5390\n",
      "Epoch [322/400], Loss: 6.5543\n",
      "Epoch [323/400], Loss: 6.5575\n",
      "Epoch [324/400], Loss: 6.6068\n",
      "Epoch [325/400], Loss: 6.5294\n",
      "Epoch [326/400], Loss: 6.5568\n",
      "Epoch [327/400], Loss: 6.4967\n",
      "Epoch [328/400], Loss: 6.5433\n",
      "Epoch [329/400], Loss: 6.5924\n",
      "Epoch [330/400], Loss: 6.5006\n",
      "Epoch [331/400], Loss: 6.5245\n",
      "Epoch [332/400], Loss: 6.5185\n",
      "Epoch [333/400], Loss: 6.5440\n",
      "Epoch [334/400], Loss: 6.5349\n",
      "Epoch [335/400], Loss: 6.5161\n",
      "Epoch [336/400], Loss: 6.5476\n",
      "Epoch [337/400], Loss: 6.6099\n",
      "Epoch [338/400], Loss: 6.5154\n",
      "Epoch [339/400], Loss: 6.5200\n",
      "Epoch [340/400], Loss: 6.6338\n",
      "Epoch [341/400], Loss: 6.5217\n",
      "Epoch [342/400], Loss: 6.5530\n",
      "Epoch [343/400], Loss: 6.6593\n",
      "Epoch [344/400], Loss: 6.5196\n",
      "Epoch [345/400], Loss: 6.6537\n",
      "Epoch [346/400], Loss: 6.5749\n",
      "Epoch [347/400], Loss: 6.5261\n",
      "Epoch [348/400], Loss: 6.5271\n",
      "Epoch [349/400], Loss: 6.5287\n",
      "Epoch [350/400], Loss: 6.5150\n",
      "Epoch [351/400], Loss: 6.5598\n",
      "Epoch [352/400], Loss: 6.5766\n",
      "Epoch [353/400], Loss: 6.5421\n",
      "Epoch [354/400], Loss: 6.5464\n",
      "Epoch [355/400], Loss: 6.5615\n",
      "Epoch [356/400], Loss: 6.5558\n",
      "Epoch [357/400], Loss: 6.5358\n",
      "Epoch [358/400], Loss: 6.5694\n",
      "Epoch [359/400], Loss: 6.5519\n",
      "Epoch [360/400], Loss: 6.5232\n",
      "Epoch [361/400], Loss: 6.5521\n",
      "Epoch [362/400], Loss: 6.5576\n",
      "Epoch [363/400], Loss: 6.5417\n",
      "Epoch [364/400], Loss: 6.5147\n",
      "Epoch [365/400], Loss: 6.5671\n",
      "Epoch [366/400], Loss: 6.5944\n",
      "Epoch [367/400], Loss: 6.5609\n",
      "Epoch [368/400], Loss: 6.5724\n",
      "Epoch [369/400], Loss: 6.5690\n",
      "Epoch [370/400], Loss: 6.5137\n",
      "Epoch [371/400], Loss: 6.5200\n",
      "Epoch [372/400], Loss: 6.5001\n",
      "Epoch [373/400], Loss: 6.5076\n",
      "Epoch [374/400], Loss: 6.5321\n",
      "Epoch [375/400], Loss: 6.5359\n",
      "Epoch [376/400], Loss: 6.4960\n",
      "Epoch [377/400], Loss: 6.5185\n",
      "Epoch [378/400], Loss: 6.5031\n",
      "Epoch [379/400], Loss: 6.4858\n",
      "Epoch [380/400], Loss: 6.6006\n",
      "Epoch [381/400], Loss: 6.5063\n",
      "Epoch [382/400], Loss: 6.5087\n",
      "Epoch [383/400], Loss: 6.5205\n",
      "Epoch [384/400], Loss: 6.5265\n",
      "Epoch [385/400], Loss: 6.5068\n",
      "Epoch [386/400], Loss: 6.5165\n",
      "Epoch [387/400], Loss: 6.5024\n",
      "Epoch [388/400], Loss: 6.5130\n",
      "Epoch [389/400], Loss: 6.4863\n",
      "Epoch [390/400], Loss: 6.5750\n",
      "Epoch [391/400], Loss: 6.5072\n",
      "Epoch [392/400], Loss: 6.5700\n",
      "Epoch [393/400], Loss: 6.5046\n",
      "Epoch [394/400], Loss: 6.6042\n",
      "Epoch [395/400], Loss: 6.4878\n",
      "Epoch [396/400], Loss: 6.5350\n",
      "Epoch [397/400], Loss: 6.4979\n",
      "Epoch [398/400], Loss: 6.5177\n",
      "Epoch [399/400], Loss: 6.5387\n",
      "Epoch [400/400], Loss: 6.5051\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "from collections import Counter\n",
    "import streamlit as st\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from typing import List, Tuple, Dict\n",
    "import random\n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self, min_word_freq: int = 3):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.min_word_freq = min_word_freq\n",
    "        \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean the input text by removing special characters except periods.\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub('[^a-zA-Z0-9 \\.]', '', text)\n",
    "        return text\n",
    "    \n",
    "    def build_vocabulary(self, text: str) -> None:\n",
    "        \"\"\"Build vocabulary from cleaned text.\"\"\"\n",
    "        # Clean and split text\n",
    "        cleaned_text = self.clean_text(text)\n",
    "        words = cleaned_text.split()\n",
    "        \n",
    "        # Count word frequencies\n",
    "        word_freq = Counter(words)\n",
    "        \n",
    "        # Create vocabulary (only include words that appear at least min_word_freq times)\n",
    "        vocab_words = [word for word, freq in word_freq.items() if freq >= self.min_word_freq]\n",
    "        \n",
    "        # Create word to index mappings\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(vocab_words)}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        \n",
    "    def create_sequences(self, text: str, context_length: int) -> Tuple[List[List[int]], List[int]]:\n",
    "        \"\"\"Create input-output sequences for training.\"\"\"\n",
    "        cleaned_text = self.clean_text(text)\n",
    "        words = cleaned_text.split()\n",
    "        \n",
    "        X, y = [], []\n",
    "        for i in range(len(words) - context_length):\n",
    "            context = words[i:i+context_length]\n",
    "            target = words[i+context_length]\n",
    "            \n",
    "            # Skip if any word is not in vocabulary\n",
    "            if all(word in self.word2idx for word in context) and target in self.word2idx:\n",
    "                X.append([self.word2idx[word] for word in context])\n",
    "                y.append(self.word2idx[target])\n",
    "                \n",
    "        return X, y\n",
    "\n",
    "class WordPredictionDataset(Dataset):\n",
    "    def __init__(self, X: List[List[int]], y: List[int]):\n",
    "        self.X = torch.LongTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class WordPredictionModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, context_length: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim * context_length, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # Shape: (batch_size, context_length, embedding_dim)\n",
    "        embedded = embedded.view(embedded.shape[0], -1)  # Flatten the embeddings\n",
    "        x = self.relu(self.fc1(embedded))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        \"\"\"Return the learned word embeddings.\"\"\"\n",
    "        return self.embedding.weight.detach().numpy()\n",
    "\n",
    "def train_model(model: nn.Module, train_loader: DataLoader, \n",
    "                num_epochs: int, learning_rate: float, device: str) -> List[float]:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "            \n",
    "    return losses\n",
    "\n",
    "def predict_next_words(model: nn.Module, processor: TextProcessor, \n",
    "                      input_text: str, k: int, context_length: int, device: str) -> List[str]:\n",
    "    \"\"\"Predict the next k words given an input text.\"\"\"\n",
    "    model.eval()\n",
    "    words = processor.clean_text(input_text).split()\n",
    "    \n",
    "    predictions = []\n",
    "    for _ in range(k):\n",
    "        # Take the last context_length words\n",
    "        context = words[-context_length:]\n",
    "        \n",
    "        # Convert to indices, handling OOV words\n",
    "        context_indices = []\n",
    "        for word in context:\n",
    "            if word in processor.word2idx:\n",
    "                context_indices.append(processor.word2idx[word])\n",
    "            else:\n",
    "                # For OOV words, randomly select a word from vocabulary\n",
    "                context_indices.append(random.choice(list(processor.word2idx.values())))\n",
    "        \n",
    "        # Convert to tensor and get prediction\n",
    "        context_tensor = torch.LongTensor([context_indices]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(context_tensor)\n",
    "            pred_idx = torch.argmax(output, dim=1).item()\n",
    "            pred_word = processor.idx2word[pred_idx]\n",
    "        \n",
    "        predictions.append(pred_word)\n",
    "        words.append(pred_word)\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "def visualize_embeddings(embeddings: np.ndarray, words: List[str], n_components: int = 2):\n",
    "    \"\"\"Visualize word embeddings using t-SNE or scatter plot.\"\"\"\n",
    "    if embeddings.shape[1] > 2:\n",
    "        tsne = TSNE(n_components=n_components, random_state=42)\n",
    "        embeddings_2d = tsne.fit_transform(embeddings)\n",
    "    else:\n",
    "        embeddings_2d = embeddings\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.5)\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
    "    \n",
    "    plt.title('Word Embeddings Visualization')\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    return plt\n",
    "\n",
    "def create_streamlit_app():\n",
    "    st.title('Next Word Prediction App')\n",
    "    \n",
    "    # Model parameters\n",
    "    context_length = st.slider('Context Length', 2, 10, 5)\n",
    "    embedding_dim = st.select_slider('Embedding Dimension', options=[32, 64, 128, 256], value=64)\n",
    "    hidden_dim = st.select_slider('Hidden Dimension', options=[512, 1024, 2048], value=1024)\n",
    "    activation = st.selectbox('Activation Function', ['ReLU', 'Tanh', 'LeakyReLU'])\n",
    "    \n",
    "    # Input text\n",
    "    input_text = st.text_area('Enter your text:', 'The quick brown fox jumps')\n",
    "    num_words = st.slider('Number of words to predict', 1, 10, 3)\n",
    "    \n",
    "    if st.button('Predict'):\n",
    "        # Load model (you would need to save and load your trained models)\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Here you would load your trained model and processor\n",
    "        # For demonstration, we'll just show the structure\n",
    "        st.write(f'Predicting {num_words} words...')\n",
    "        st.write('Model parameters:')\n",
    "        st.write(f'Context length: {context_length}')\n",
    "        st.write(f'Embedding dimension: {embedding_dim}')\n",
    "        st.write(f'Hidden dimension: {hidden_dim}')\n",
    "        st.write(f'Activation: {activation}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # For training\n",
    "    # Load your dataset here\n",
    "    with open(\"s.txt\",\"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Initialize processor and create sequences\n",
    "    processor = TextProcessor(min_word_freq=3)\n",
    "    processor.build_vocabulary(text)\n",
    "    X, y = processor.create_sequences(text, context_length=5)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = WordPredictionDataset(X, y)\n",
    "    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = WordPredictionModel(\n",
    "        vocab_size=len(processor.word2idx),\n",
    "        embedding_dim=64,\n",
    "        context_length=5,\n",
    "        hidden_dim=1024\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device('mps')\n",
    "    losses = train_model(model, train_loader, num_epochs=400, learning_rate=0.001, device=device)\n",
    "    \n",
    "    # For Streamlit app\n",
    "    #create_streamlit_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordPredictionModel(\n",
       "  (embedding): Embedding(13748, 64)\n",
       "  (fc1): Linear(in_features=320, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=13748, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'man', 'the', 'the', 'the']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"hello there, how are you doing? \"\n",
    "no_of_words = 5\n",
    "predictions = predict_next_words(model, processor, input_text, no_of_words, context_length=5, device=device)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[-0.9370, -2.7978,  0.8693,  ...,  0.0991,  0.4725, -1.3914],\n",
       "                      [-0.3325, -2.9091,  0.7640,  ..., -0.2837, -3.5142,  0.7057],\n",
       "                      [ 1.8181, -0.3444,  1.3652,  ..., -1.3464, -0.3616, -1.0449],\n",
       "                      ...,\n",
       "                      [ 2.4203, -2.3470, -2.1992,  ...,  2.2182, -0.2923, -2.4632],\n",
       "                      [ 1.2427,  0.4998,  1.6122,  ..., -0.6251,  1.2276, -1.2728],\n",
       "                      [-1.3240, -2.5738, -1.7213,  ...,  1.2415,  1.8873, -2.7529]],\n",
       "                     device='mps:0')),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 1.3234,  0.9590,  0.0095,  ..., -0.1819, -0.5921,  0.4217],\n",
       "                      [-0.6543, -1.0630, -0.9033,  ..., -0.7070,  1.1529, -1.0007],\n",
       "                      [-0.7353,  0.7766,  1.5406,  ...,  0.3213,  0.5183, -0.9535],\n",
       "                      ...,\n",
       "                      [-1.0038,  1.8119,  0.8362,  ..., -0.8274, -1.0179, -1.0997],\n",
       "                      [-0.2965,  0.6519,  1.4467,  ..., -0.0043, -0.4302, -1.3972],\n",
       "                      [ 0.1619, -0.1789,  1.1078,  ..., -0.6567,  0.5078, -0.2509]],\n",
       "                     device='mps:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([-3.6233,  0.8624, -4.2079,  ..., -0.1672, -1.9826, -4.8829],\n",
       "                     device='mps:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.1572, -0.2063, -0.0236,  ...,  0.0137,  0.3627,  0.2077],\n",
       "                      [-0.0098,  0.0475,  0.0350,  ..., -0.0531, -0.0434, -0.0099],\n",
       "                      [-0.0831, -0.2485,  0.3320,  ...,  0.1018, -0.0389,  0.1607],\n",
       "                      ...,\n",
       "                      [-0.0861,  0.6725, -0.1622,  ..., -0.1644,  0.0922,  0.1708],\n",
       "                      [-0.0015,  0.4893,  0.0011,  ..., -0.1969,  0.2619, -0.0354],\n",
       "                      [ 0.2522, -0.2704, -0.0337,  ..., -0.0625, -0.2577,  0.0482]],\n",
       "                     device='mps:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([-4.1599, -1.7873, -4.2509,  ..., -7.1300, -5.1114, -4.2934],\n",
       "                     device='mps:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-5.3306, -6.6506, -7.0368,  ..., -6.5929, -3.9040, -3.4893],\n",
       "                      [-5.8048, -4.6468, -7.7331,  ..., -7.5560, -1.2823, -4.3102],\n",
       "                      [-4.1435, -4.0834, -6.2910,  ..., -5.2496, -3.5959, -3.0618],\n",
       "                      ...,\n",
       "                      [-3.4532, -1.6779, -2.9224,  ..., -2.7242, -2.8557, -2.2022],\n",
       "                      [-3.1769, -2.9485, -5.0771,  ..., -4.0279, -2.8462, -2.3519],\n",
       "                      [-3.3962, -1.6558, -2.9512,  ..., -2.6871, -2.8096, -2.1675]],\n",
       "                     device='mps:0')),\n",
       "             ('fc3.bias',\n",
       "              tensor([-29.1915, -26.8055, -32.2121,  ..., -74.9569, -34.3255, -74.9592],\n",
       "                     device='mps:0'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
